{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clip 모델\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import CLIPProcessor, CLIPModel\n",
    "# import torch\n",
    "# from PIL import Image\n",
    "\n",
    "# model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "# processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 식재료 리스트 정의 (예: 사과, 바나나, 양파, 당근 등)\n",
    "# ingredients = [\"apple\", \"banana\", \"onion\", \"carrot\", \"tomato\", \"potato\", \"broccoli\", \"lettuce\", \"eggplant\",\"tomato\", \"garlic\"]\n",
    "\n",
    "# # 이미지 로드\n",
    "# image_path = \"/content/article850-01.jpg\"  # 이미지 파일 경로\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "# # 이미지와 각 식재료의 텍스트 유사도 계산\n",
    "# inputs = processor(text=ingredients, images=image, return_tensors=\"pt\", padding=True)\n",
    "# clipOutputs = model(**inputs)\n",
    "\n",
    "# # 유사도 계산\n",
    "# logits_per_image = clipOutputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "# probs = logits_per_image.softmax(dim=1)  # 유사도를 확률 형태로 변환\n",
    "\n",
    "# # 가장 높은 유사도를 가진 식재료 선택\n",
    "# top_probs, top_labels = probs.topk(1, dim=1)  # top 1 식재료\n",
    "\n",
    "# # 결과 출력\n",
    "# predicted_ingredient = ingredients[top_labels[0].item()]\n",
    "# print(\"Detected ingredient:\", predicted_ingredient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
